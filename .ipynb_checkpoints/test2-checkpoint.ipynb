{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f8b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import ResNet50, VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f38a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52493 images belonging to 5 classes.\n",
      "Found 22497 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "data_directory = r'archive\\train'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4ace4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1641/1641 [==============================] - 1516s 923ms/step - loss: 0.2499 - accuracy: 0.9043 - val_loss: 0.2230 - val_accuracy: 0.9279\n",
      "Epoch 2/3\n",
      "1641/1641 [==============================] - 1279s 779ms/step - loss: 0.1185 - accuracy: 0.9628 - val_loss: 0.1359 - val_accuracy: 0.9586\n",
      "Epoch 3/3\n",
      "1641/1641 [==============================] - 1295s 789ms/step - loss: 0.1119 - accuracy: 0.9669 - val_loss: 0.1364 - val_accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "alexnet_model = Sequential()\n",
    "alexnet_model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
    "alexnet_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "alexnet_model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
    "alexnet_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "alexnet_model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "alexnet_model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "alexnet_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "alexnet_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "alexnet_model.add(Flatten())\n",
    "alexnet_model.add(Dense(4096, activation='relu'))\n",
    "alexnet_model.add(Dropout(0.5))\n",
    "alexnet_model.add(Dense(4096, activation='relu'))\n",
    "alexnet_model.add(Dropout(0.5))\n",
    "alexnet_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "alexnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "alexnet_history = alexnet_model.fit(train_generator, validation_data=validation_generator, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dd65dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "alexnet_model.save('alexnet_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2594ce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 5 classes.\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0904 - accuracy: 0.9600\n",
      "Test Loss: 0.09042396396398544\n",
      "Test Accuracy: 0.9599999785423279\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "saved_model = tf.keras.models.load_model('alexnet_model.h5')\n",
    "\n",
    "# Test the model on new data\n",
    "test_directory =  r'archive\\test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate the saved model\n",
    "scores = saved_model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", scores[0])\n",
    "print(\"Test Accuracy:\", scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ece618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 74ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.91539896e-01, 2.13779754e-06, 3.16425030e-05, 2.86038521e-05,\n",
       "        8.39765277e-03],\n",
       "       [9.68086481e-01, 4.26077080e-04, 1.10732147e-03, 3.04619316e-03,\n",
       "        2.73338556e-02],\n",
       "       [1.84629500e-01, 2.91937922e-05, 1.07955157e-05, 1.06019324e-04,\n",
       "        8.15224528e-01],\n",
       "       [9.92770493e-01, 1.38189068e-06, 8.48506606e-05, 1.14904969e-05,\n",
       "        7.13177538e-03],\n",
       "       [9.71647382e-01, 6.52114477e-06, 1.68600556e-04, 3.72680952e-05,\n",
       "        2.81401202e-02],\n",
       "       [9.77940023e-01, 7.85245429e-05, 9.74769413e-04, 4.64776211e-04,\n",
       "        2.05419753e-02],\n",
       "       [5.95463812e-01, 1.98034148e-04, 7.52603577e-04, 6.65900472e-04,\n",
       "        4.02919620e-01],\n",
       "       [2.14261264e-01, 6.28716271e-06, 2.46522495e-06, 3.50250666e-05,\n",
       "        7.85695016e-01],\n",
       "       [8.83774757e-01, 4.22853074e-04, 3.00153741e-03, 1.62796467e-03,\n",
       "        1.11172900e-01],\n",
       "       [9.61094558e-01, 1.05437357e-04, 2.43932661e-03, 5.15449152e-04,\n",
       "        3.58452573e-02],\n",
       "       [6.51392135e-12, 9.99985337e-01, 1.66503859e-11, 1.46579350e-05,\n",
       "        4.59637381e-14],\n",
       "       [4.97236306e-06, 9.91396129e-01, 8.69758060e-06, 8.58986285e-03,\n",
       "        2.99155744e-07],\n",
       "       [3.94106365e-07, 9.96886313e-01, 8.35139929e-07, 3.11251241e-03,\n",
       "        1.30491982e-08],\n",
       "       [5.53318591e-09, 9.99710739e-01, 1.23903039e-08, 2.89284420e-04,\n",
       "        1.51993293e-10],\n",
       "       [1.00528279e-08, 9.99581516e-01, 2.04353778e-08, 4.18540876e-04,\n",
       "        2.47467880e-10],\n",
       "       [5.00998283e-07, 9.96948302e-01, 9.46903754e-07, 3.05032823e-03,\n",
       "        2.01894803e-08],\n",
       "       [1.26276814e-06, 9.95135248e-01, 2.37248219e-06, 4.86111687e-03,\n",
       "        5.60989157e-08],\n",
       "       [2.49305185e-06, 9.94105935e-01, 4.22009089e-06, 5.88715030e-03,\n",
       "        1.35478899e-07],\n",
       "       [6.53380861e-09, 9.99644756e-01, 1.38838523e-08, 3.55280266e-04,\n",
       "        1.47064680e-10],\n",
       "       [1.04061464e-05, 9.87655222e-01, 1.77371221e-05, 1.23159969e-02,\n",
       "        6.62076218e-07],\n",
       "       [1.90635352e-09, 1.36068336e-15, 9.99999881e-01, 9.75753238e-08,\n",
       "        1.57420957e-17],\n",
       "       [4.53319984e-24, 0.00000000e+00, 1.00000000e+00, 6.28217301e-21,\n",
       "        0.00000000e+00],\n",
       "       [2.36584955e-23, 0.00000000e+00, 1.00000000e+00, 1.37476640e-21,\n",
       "        0.00000000e+00],\n",
       "       [2.49291220e-16, 4.82958904e-28, 1.00000000e+00, 5.33366415e-14,\n",
       "        1.32019394e-30],\n",
       "       [1.54917579e-04, 7.38811623e-10, 9.99816835e-01, 2.82869423e-05,\n",
       "        4.34786829e-09],\n",
       "       [4.01806233e-09, 8.08653835e-18, 1.00000000e+00, 1.20017307e-09,\n",
       "        5.63361349e-17],\n",
       "       [9.82036067e-12, 8.50069948e-22, 1.00000000e+00, 4.79881516e-11,\n",
       "        2.26117348e-22],\n",
       "       [3.96369160e-08, 1.77635633e-14, 9.99999762e-01, 2.39802006e-07,\n",
       "        2.26502243e-15],\n",
       "       [2.28995667e-08, 9.12323412e-20, 1.00000000e+00, 4.81678863e-11,\n",
       "        6.07954986e-17],\n",
       "       [6.95464042e-19, 1.61641111e-32, 1.00000000e+00, 1.80785246e-16,\n",
       "        3.87004108e-35],\n",
       "       [4.68454236e-05, 9.48370725e-05, 1.28376259e-11, 9.99858141e-01,\n",
       "        8.25333757e-08],\n",
       "       [1.30362320e-03, 9.03015374e-04, 1.15576624e-08, 9.97782171e-01,\n",
       "        1.12003363e-05],\n",
       "       [4.17112000e-03, 2.84668594e-03, 3.13331526e-07, 9.92908597e-01,\n",
       "        7.33321140e-05],\n",
       "       [1.45764777e-03, 2.19316082e-03, 6.62751347e-08, 9.96329606e-01,\n",
       "        1.95578596e-05],\n",
       "       [8.30348799e-05, 5.22189839e-05, 3.49259272e-12, 9.99864578e-01,\n",
       "        1.14048511e-07],\n",
       "       [1.34122965e-04, 2.38954846e-04, 1.26486988e-10, 9.99626517e-01,\n",
       "        3.64841242e-07],\n",
       "       [1.28312613e-05, 1.56775313e-05, 1.19933536e-13, 9.99971390e-01,\n",
       "        7.93178589e-09],\n",
       "       [9.27920119e-05, 1.02896694e-04, 1.46982027e-11, 9.99804080e-01,\n",
       "        1.84020053e-07],\n",
       "       [1.34403217e-05, 1.53919638e-04, 3.53184994e-12, 9.99832630e-01,\n",
       "        1.14159828e-08],\n",
       "       [3.90826957e-04, 1.50757420e-04, 1.23700758e-10, 9.99457061e-01,\n",
       "        1.48576635e-06],\n",
       "       [2.03584097e-02, 2.32716161e-07, 1.14568155e-09, 1.32986406e-06,\n",
       "        9.79640067e-01],\n",
       "       [4.00411570e-03, 1.46698231e-09, 4.68217208e-13, 1.23358124e-08,\n",
       "        9.95995879e-01],\n",
       "       [1.72615994e-03, 2.85841517e-10, 1.99566637e-14, 2.79538259e-09,\n",
       "        9.98273849e-01],\n",
       "       [6.78939698e-03, 9.38471256e-09, 7.92844956e-12, 8.03826623e-08,\n",
       "        9.93210495e-01],\n",
       "       [1.64823923e-02, 5.10743348e-07, 1.74533477e-09, 2.73892306e-06,\n",
       "        9.83514309e-01],\n",
       "       [4.49522510e-02, 2.62944559e-06, 4.27821902e-08, 1.17246527e-05,\n",
       "        9.55033362e-01],\n",
       "       [4.40390594e-03, 2.35869768e-09, 1.02213930e-12, 1.82416038e-08,\n",
       "        9.95596111e-01],\n",
       "       [9.15840119e-02, 6.25901248e-06, 3.96088694e-07, 2.64603932e-05,\n",
       "        9.08382893e-01],\n",
       "       [2.02669248e-01, 5.43750211e-05, 1.82949443e-05, 2.08907251e-04,\n",
       "        7.97049165e-01],\n",
       "       [3.27860788e-02, 1.72972739e-06, 1.63228115e-08, 8.59143802e-06,\n",
       "        9.67203617e-01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the saved model\n",
    "predictions = saved_model.predict(test_generator)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11165407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1641/1641 [==============================] - 3064s 2s/step - loss: 0.5459 - accuracy: 0.8578 - val_loss: 0.4688 - val_accuracy: 0.8757\n",
      "Epoch 2/3\n",
      "1641/1641 [==============================] - 3042s 2s/step - loss: 0.2688 - accuracy: 0.9379 - val_loss: 0.3776 - val_accuracy: 0.8892\n",
      "Epoch 3/3\n",
      "1641/1641 [==============================] - 3004s 2s/step - loss: 0.2066 - accuracy: 0.9475 - val_loss: 0.3254 - val_accuracy: 0.8994\n"
     ]
    }
   ],
   "source": [
    "resnet_model = Sequential()\n",
    "resnet_model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
    "resnet_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "resnet_model.layers[0].trainable = False\n",
    "\n",
    "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "resnet_history = resnet_model.fit(train_generator, validation_data=validation_generator, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99675017",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.save('resnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab3d706",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 5 classes.\n",
      "2/2 [==============================] - 3s 717ms/step - loss: 0.1599 - accuracy: 0.9200\n",
      "Test Loss: 0.15987545251846313\n",
      "Test Accuracy: 0.9200000166893005\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "saved_model = tf.keras.models.load_model('resnet_model.h5')\n",
    "\n",
    "# Test the model on new data\n",
    "test_directory =  r'archive\\test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate the saved model\n",
    "scores = saved_model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", scores[0])\n",
    "print(\"Test Accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4d9cf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1641/1641 [==============================] - 4822s 3s/step - loss: 0.5993 - accuracy: 0.9161 - val_loss: 0.3832 - val_accuracy: 0.8873\n",
      "Epoch 2/3\n",
      "1641/1641 [==============================] - 5091s 3s/step - loss: 0.2076 - accuracy: 0.9661 - val_loss: 0.2755 - val_accuracy: 0.8981\n",
      "Epoch 3/3\n",
      "1641/1641 [==============================] - 5406s 3s/step - loss: 0.1377 - accuracy: 0.9717 - val_loss: 0.2260 - val_accuracy: 0.9085\n"
     ]
    }
   ],
   "source": [
    "vgg_model = Sequential()\n",
    "vgg_model.add(VGG16(include_top=False, pooling='avg', weights='imagenet'))\n",
    "vgg_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "vgg_model.layers[0].trainable = False\n",
    "\n",
    "vgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "vgg_history = vgg_model.fit(train_generator, validation_data=validation_generator, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20616054",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.save('vgg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3358d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 5 classes.\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0835 - accuracy: 0.9800\n",
      "Test Loss: 0.08350679278373718\n",
      "Test Accuracy: 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "saved_model = tf.keras.models.load_model('vgg_model.h5')\n",
    "\n",
    "# Test the model on new data\n",
    "test_directory =  r'archive\\test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate the saved model\n",
    "scores = saved_model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", scores[0])\n",
    "print(\"Test Accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0c1a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_directory = \\'/path/to/test_dataset\\'\\n\\ntest_datagen = ImageDataGenerator(rescale=1./255)\\n\\ntest_generator = test_datagen.flow_from_directory(\\n    test_directory,\\n    target_size=(224, 224),\\n    batch_size=32,\\n    class_mode=\\'categorical\\',\\n    shuffle=False\\n)\\n\\n# Evaluate AlexNet model\\nalexnet_scores = alexnet_model.evaluate(test_generator)\\nprint(\"AlexNet Test Loss:\", alexnet_scores[0])\\nprint(\"AlexNet Test Accuracy:\", alexnet_scores[1])\\n\\n# Evaluate ResNet model\\nresnet_scores = resnet_model.evaluate(test_generator)\\nprint(\"ResNet Test Loss:\", resnet_scores[0])\\nprint(\"ResNet Test Accuracy:\", resnet_scores[1])\\n\\n# Evaluate VGGNet model\\nvgg_scores = vgg_model.evaluate(test_generator)\\nprint(\"VGGNet Test Loss:\", vgg_scores[0])\\nprint(\"VGGNet Test Accuracy:\", vgg_scores[1])\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "resnet_model = Sequential()\n",
    "resnet_model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
    "resnet_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "resnet_model.layers[0].trainable = False\n",
    "\n",
    "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "resnet_history = resnet_model.fit(train_generator, validation_data=validation_generator, epochs=3)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "vgg_model = Sequential()\n",
    "vgg_model.add(VGG16(include_top=False, pooling='avg', weights='imagenet'))\n",
    "vgg_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "vgg_model.layers[0].trainable = False\n",
    "\n",
    "vgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "vgg_history = vgg_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "test_directory = '/path/to/test_dataset'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate AlexNet model\n",
    "alexnet_scores = alexnet_model.evaluate(test_generator)\n",
    "print(\"AlexNet Test Loss:\", alexnet_scores[0])\n",
    "print(\"AlexNet Test Accuracy:\", alexnet_scores[1])\n",
    "\n",
    "# Evaluate ResNet model\n",
    "resnet_scores = resnet_model.evaluate(test_generator)\n",
    "print(\"ResNet Test Loss:\", resnet_scores[0])\n",
    "print(\"ResNet Test Accuracy:\", resnet_scores[1])\n",
    "\n",
    "# Evaluate VGGNet model\n",
    "vgg_scores = vgg_model.evaluate(test_generator)\n",
    "print(\"VGGNet Test Loss:\", vgg_scores[0])\n",
    "print(\"VGGNet Test Accuracy:\", vgg_scores[1])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0a5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_directory = r'archive\\test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b29cc27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alexnet_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate AlexNet model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m alexnet_scores \u001b[38;5;241m=\u001b[39m \u001b[43malexnet_model\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_generator)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlexNet Test Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, alexnet_scores[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlexNet Test Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, alexnet_scores[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alexnet_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate AlexNet model\n",
    "alexnet_scores = alexnet_model.evaluate(test_generator)\n",
    "print(\"AlexNet Test Loss:\", alexnet_scores[0])\n",
    "print(\"AlexNet Test Accuracy:\", alexnet_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b67670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
